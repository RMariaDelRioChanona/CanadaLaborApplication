{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving file ../results/csv/u_per_occ_numknFO_automation_deltau160v120gamma160_tau3_shockduration30_dimfact0.csv\n",
      "saving file ../results/csv/u_ltu_perc_changeknFO_automation_deltau160v120gamma160_tau3_shockduration30_dimfact0.csv\n",
      "saving file ../results/csv/u_per_occ_numOMNFO_automation_deltau160v120gamma160_tau3_shockduration30_dimfact0.csv\n",
      "saving file ../results/csv/u_ltu_perc_changeOMNFO_automation_deltau160v120gamma160_tau3_shockduration30_dimfact0.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import sys\n",
    "# %matplotlib inline\n",
    "sys.path += ['../scripts/']\n",
    "\n",
    "import labornet as lbn\n",
    "# paths\n",
    "path_data = \"data/\"\n",
    "path_local = \"../\"\n",
    "path_exp_sim = \"../results/csv/\"\n",
    "path_exp_fig = \"../results/fig/\"\n",
    "\n",
    "# variable that says if results are saved in csv or fig\n",
    "save_csv =  True\n",
    "save_fig = False\n",
    "run_random = False\n",
    "run_random_ret = True\n",
    "# setting seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "random.seed(12345)\n",
    "# paths\n",
    "path_data = \"../data/\"\n",
    "path_local = \"../\"\n",
    "path_exp_sim = \"../results/csv/\"\n",
    "\n",
    "# simulation conditions\n",
    "shock = \"FO_automation\"#\"beveridgeCurve\"\n",
    "# shock = \"SMLautomation\"\n",
    "network_and_employment = \"new_emp\"\n",
    "network_and_employment = \"new_emp_selfloops\"\n",
    "file_occmobnet = \"occupational_mobility_network.csv\"\n",
    "\n",
    "\n",
    "\n",
    "ipums_lab_file = \"ipums_variables.csv\"\n",
    "ipums_mSML = \"ipums_labs_mSML_manual.csv\"\n",
    "df_labs = pd.read_csv(path_data + ipums_lab_file)\n",
    "df_labs = pd.read_csv(path_data + ipums_lab_file)\n",
    "wage = np.array(df_labs[\"log_median_earnings\"])\n",
    "p = np.array(df_labs[\"auto_prob_average\"])\n",
    "df_sml = pd.read_csv(path_data + ipums_mSML)\n",
    "\n",
    "\n",
    "ipums_employment2016 = \"ipums_employment_2016.csv\"\n",
    "df_labs_emp = pd.read_csv(path_data+ipums_employment2016)\n",
    "employment = np.array(df_labs_emp[\"IPUMS_CPS_av_monthly_employment_whole_period\"])\n",
    "\n",
    "# employment = np.array(df_labs_emp[\"IPUMS_CPS_av_monthly_employment_2016\"])\n",
    "if shock == \"FO_automation\":\n",
    "    p = np.array(df_labs[\"auto_prob_average\"])\n",
    "elif shock == \"SMLautomation\":\n",
    "    p = np.array(df_sml['mSML'])/5\n",
    "\n",
    "δ_u = 0.016 + 0.00000001 # adding zeros since useful for defining names\n",
    "δ_v = 0.012 + 0.00000001\n",
    "γ_u = 10*δ_u\n",
    "γ_v = γ_u\n",
    "parameters = [δ_u, δ_v, γ_u, γ_v]\n",
    "τ = 3 # the one is due to python starting to count until 0\n",
    "r = 0.5502916755953751\n",
    "# fraction of labor force with which to run solution (to align with simulation)\n",
    "diminishing_factor = 1.0#0.01#1.0\n",
    "\n",
    "# occupational mobility network\n",
    "A_omn = np.genfromtxt(path_data + file_occmobnet, delimiter=',')\n",
    "n = A_omn.shape[0]\n",
    "# complete network\n",
    "A_kn = np.ones([n,n])/n\n",
    "\n",
    "# shock and time conditions\n",
    "t_shock = 100 # time at which shock starts\n",
    "t_simulation = 600\n",
    "shock_duration_years = 30\n",
    "shock_duration = shock_duration_years * 52/6.75 # NOTE one time step ~6.75 weeks\n",
    "time_array = [t*6.75/52 for t in range(t_simulation)]\n",
    "t_steady_start = 25\n",
    "t_steady_end = 75\n",
    "# for sharp shocks\n",
    "# t_transition_start = int(t_shock + 0.25*shock_duration)\n",
    "# t_transition_end = int(t_shock + 0.75*shock_duration)\n",
    "t_transition_start = int(t_shock +0*shock_duration)\n",
    "t_transition_end = int(t_shock + 1*shock_duration)\n",
    "\n",
    "# get demand in sigmoid\n",
    "sigmoid_half_life, k = lbn.calibrate_sigmoid(shock_duration)\n",
    "\n",
    "employment_0 = employment[:]\n",
    "unemployment_0 = δ_u * employment_0\n",
    "vacancies_0 = δ_v * employment_0\n",
    "variables_0 = [employment_0, unemployment_0, vacancies_0]\n",
    "# labor force is all workers, employed + unemployed\n",
    "L = np.sum(employment_0 + unemployment_0)\n",
    "\n",
    "# initial demand and target demand\n",
    "D_0 = employment_0 + unemployment_0\n",
    "# set random automation probabilities\n",
    "D_f = lbn.labor_restructure(D_0, p)\n",
    "\n",
    "\n",
    "parameter_names = \"_deltau\" + str(δ_u)[3:6] + \"v\" + str(δ_v)[3:6] + \\\n",
    "    \"gamma\" + str(γ_u)[2:5] + \"_tau\" + str(round(τ)) + \"_shockduration\" + \\\n",
    "    str(shock_duration_years) + \"_dimfact\" + str(diminishing_factor)[2:]\n",
    "\n",
    "\n",
    "\n",
    "def lt_unemployment(U_all, τ):\n",
    "    \"\"\" takes the array of all unemployment spells and with tau gives\n",
    "    array with number of long term unemployed as defined by τ threshold\n",
    "    \"\"\"\n",
    "    U_lt = u_longterm_from_jobspell(U_all, τ)\n",
    "    # the -1 in tau is due to python counting starting on 0\n",
    "    lt_unemployment = np.sum(U_all[:, τ:, :], axis=1)\n",
    "    return lt_unemployment\n",
    "\n",
    "# TODO check tau numbering and change in labornet in case needed\n",
    "def u_longterm_from_jobspell(U_ltm, τ):\n",
    "    # NOTE -1 since python starts counting on 1\n",
    "    return np.sum(U_ltm[:, τ:, :], axis=1)\n",
    "\n",
    "def save_result(Variables, U_all, D, τ, matrix, params=parameter_names, shock=shock):\n",
    "    \"\"\"Function that saves unemployment, vacnacies, employment, longterm unep,\n",
    "    and demand into csv files\n",
    "    \"\"\"\n",
    "    E, U, V = Variables\n",
    "    names = [\"u_per_occ_num\",\"v_per_occ_num\", \"e_per_occ_num\", \\\n",
    "            \"ddagger_per_occ_num\", \"ltu_per_occ_num\"]\n",
    "    U_longterm = lt_unemployment(U_all, τ)\n",
    "    for i, array in enumerate([U, V, E, D, U_longterm]):\n",
    "        df = pd.DataFrame()\n",
    "        df[\"id\"] = np.arange(0, 464)\n",
    "        df[\"label\"] = df_labs[\"label\"]\n",
    "        for t in range(t_simulation):\n",
    "            df[\"t\" + str(t)] = array[t, :]\n",
    "        df.to_csv(path_exp_sim + names[i] + matrix + shock + params+ \".csv\" )\n",
    "    print(\"saving file \" + path_exp_sim + names[0] + matrix + shock + params + \".csv\")\n",
    "\n",
    "def save_percentage_change(Variables, U_all, τ, t_steady_start, t_steady_end, \\\n",
    "    t_transition_start, t_transition_end, matrix, params=parameter_names, \\\n",
    "        shock=shock):\n",
    "    \"\"\"Function that computes percentage change in unemployment and longterm\n",
    "    unemployment. For steady state averages u and ltu from steady start to\n",
    "    steady end\n",
    "    \"\"\"\n",
    "    E, U, V = Variables\n",
    "    U_lt = u_longterm_from_jobspell(U_all, τ)\n",
    "    u_perc_change_num = lbn.percentage_change_u(E, U, t_steady_start, \\\n",
    "                t_steady_end, t_transition_start, t_transition_end)\n",
    "    ltu_perc_change_num = lbn.percentage_change_ltu(E, U, U_lt, \\\n",
    "                t_steady_start, t_steady_end, t_transition_start, t_transition_end)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"id\"] = np.arange(0, 464)\n",
    "    df[\"label\"] = df_labs[\"label\"]\n",
    "    df[\"u_perc_change\"] = u_perc_change_num\n",
    "    df[\"ltu_perc_change\"] = ltu_perc_change_num\n",
    "    df.to_csv(path_exp_sim + \"u_ltu_perc_change\" + matrix + shock + params+ \".csv\" )\n",
    "    print(\"saving file \"+ path_exp_sim + \"u_ltu_perc_change\" + matrix + shock + params+ \".csv\")\n",
    "\n",
    "\n",
    "# run and save model for kn\n",
    "Variables_kn, U_all_kn, D_kn = lbn.run_numerical_solution(\\\n",
    "    lbn.fire_and_hire_workers, t_simulation, parameters,\\\n",
    "    variables_0, \\\n",
    "    lbn.target_demand_automation, D_0, D_f, t_shock, k, sigmoid_half_life, \\\n",
    "    lbn.matching_probability, A_kn, τ)\n",
    "\n",
    "save_result(Variables_kn, U_all_kn, D_kn, τ, \"kn\")\n",
    "save_percentage_change(Variables_kn, U_all_kn, τ, t_steady_start, t_steady_end, \\\n",
    "    t_transition_start, t_transition_end, \"kn\")\n",
    "\n",
    "\n",
    "# run and save model for OMN\n",
    "Variables_omn, U_all_omn, D_omn = lbn.run_numerical_solution(\\\n",
    "    lbn.fire_and_hire_workers, t_simulation, parameters,\\\n",
    "    variables_0, \\\n",
    "    lbn.target_demand_automation, D_0, D_f, t_shock, k, sigmoid_half_life, \\\n",
    "    lbn.matching_probability, A_omn, τ)\n",
    "\n",
    "save_result(Variables_omn, U_all_omn, D_omn, τ, \"OMN\")\n",
    "save_percentage_change(Variables_omn, U_all_omn, τ, t_steady_start, t_steady_end, \\\n",
    "    t_transition_start, t_transition_end, \"OMN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
